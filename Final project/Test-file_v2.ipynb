{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2285fccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse.linalg as splin\n",
    "import scipy.sparse as sparse\n",
    "import json\n",
    "\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import ndcg_score as ndcg\n",
    "from sklearn.metrics import recall_score as recall\n",
    "# from ignite.metrics.recall import Recall as t_recall\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac1b04a",
   "metadata": {},
   "source": [
    "# data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2975121c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-a87149dd157b>:13: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df_ratings = pd.read_csv('ml-1m/ratings.dat', sep=\"::\", header=None)\n"
     ]
    }
   ],
   "source": [
    "dict_df_rating = dict()\n",
    "\n",
    "#20 millions\n",
    "\n",
    "# #links = pd.read_csv('ml-20m/links.csv')\n",
    "# df_ratings = pd.read_csv('ml-20m/ratings.csv')\n",
    "# df_ratings.columns = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "# df_ratings.head()\n",
    "\n",
    "\n",
    "#1 million MovieLens \n",
    "\n",
    "df_ratings = pd.read_csv('ml-1m/ratings.dat', sep=\"::\", header=None)\n",
    "df_ratings.columns = ['user_id', 'object_id', 'rating', 'timestamp']\n",
    "df_ratings.drop('timestamp', axis='columns', inplace=True)\n",
    "df_ratings.dropna(inplace=True)\n",
    "df_ratings['user_id'] = df_ratings['user_id'].astype(\"category\").cat.codes\n",
    "df_ratings['object_id'] = df_ratings['object_id'].astype(\"category\").cat.codes\n",
    "\n",
    "dict_df_rating['ML1M'] = dict()\n",
    "dict_df_rating['ML1M']['original'] = df_ratings\n",
    "\n",
    "# #Books http://www2.informatik.uni-freiburg.de/~cziegler/BX/\n",
    "\n",
    "# df_ratings = pd.read_csv('Books Data/BX-Book-Ratings.csv', sep=';')\n",
    "# df_ratings.columns = ['user_id', 'object_id', 'rating']\n",
    "# dict_df_rating['BX'] = dict()\n",
    "# dict_df_rating['BX']['original'] = df_ratings\n",
    "\n",
    "# #Music  http://jmcauley.ucsd.edu/data/amazon/\n",
    "\n",
    "# df_ratings = pd.read_csv('Digital music/ratings_Digital_Music.csv', sep=',', header=None)\n",
    "# df_ratings.columns = ['user_id', 'object_id', 'rating', 'timestamp']\n",
    "# dict_df_rating['DM'] = dict()\n",
    "# dict_df_rating['DM']['original'] = df_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae9ce2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparcity for ML1M dataset: 0.044683625622312845\n"
     ]
    }
   ],
   "source": [
    "for ds in dict_df_rating:\n",
    "    df_ratings = dict_df_rating[ds]['original']\n",
    "    all_cells = df_ratings.object_id.nunique() * df_ratings.user_id.nunique()\n",
    "    sparcity_rate = len(df_ratings) / all_cells\n",
    "    print(f'sparcity for {ds} dataset: {sparcity_rate}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38c186e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ds in dict_df_rating:\n",
    "#     print(ds)\n",
    "    \n",
    "#     df_ratings = dict_df_rating[ds]['original'].copy()\n",
    "    \n",
    "#     df_ratings['user_id'] =  df_ratings['user_id'].astype('str')\n",
    "#     df_ratings['object_id'] =  df_ratings['object_id'].astype('str')\n",
    "\n",
    "#     dense_rating = df_ratings.pivot(index='user_id', columns='object_id', values='rating')\n",
    "#     dense_rating = dense_rating.fillna(0)\n",
    "#     dict_df_rating[ds]['dense'] = dense_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fb1ced8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#forming sparse matrixes\n",
    "\n",
    "for ds in dict_df_rating:\n",
    "    \n",
    "    df_ratings = dict_df_rating[ds]['original'].copy()\n",
    "\n",
    "#     dict_obj = {obj:i for i, obj in enumerate(sorted(df_ratings.object_id.unique()))}\n",
    "#     dict_user = {obj:i for i, obj in enumerate(sorted(df_ratings.user_id.unique()))}\n",
    "\n",
    "#     df_ratings['user_id'] = df_ratings['user_id'].astype(\"category\").cat.codes\n",
    "#     df_ratings['object_id'] = df_ratings['object_id'].astype(\"category\").cat.codes\n",
    "    \n",
    "#     dict_df_rating[ds]['original'] = df_ratings\n",
    "    \n",
    "    rows = df_ratings['user_id'].astype(\"int\")\n",
    "    cols = df_ratings['object_id'].astype(\"int\")\n",
    "\n",
    "    ratings = df_ratings.rating.astype(\"int\")\n",
    "    \n",
    "    data_sparse = sparse.csr_matrix((ratings, (rows, cols)), shape=(df_ratings.user_id.nunique(), \n",
    "                                                                df_ratings.object_id.nunique()), dtype='int32')\n",
    "    \n",
    "    dict_df_rating[ds]['sparse'] = data_sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59977498",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9926012e",
   "metadata": {},
   "source": [
    "## ALS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65d57d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def implicit_als(sparse_data, alpha_val=40, iterations=10, lambda_val=0.1, features=10):\n",
    "    \"\"\" Implementation of Alternating Least Squares with implicit data. We iteratively\n",
    "    compute the user (x_u) and item (y_i)from tor vectors using the following formulas:\n",
    " \n",
    "    x_u = ((Y.T*Y + Y.T*(Cu - I) * Y) + lambda*I)^-1 * (X.T * Cu * p(u))\n",
    "    y_i = ((X.T*X + X.T*(Ci - I) * X) + lambda*I)^-1 * (Y.T * Ci * p(i))\n",
    " \n",
    "    Args:\n",
    "        sparse_data (csr_matrix): Our sparse user-by-item matrix\n",
    " \n",
    "        alpha_val (int): The rate in which we'll increase our confidence\n",
    "        in a preference with more interactions.\n",
    " \n",
    "        iterations (int): How many times we alternate between fixing and \n",
    "        updating our user and item vectors\n",
    " \n",
    "        lambda_val (float): Regularization value\n",
    " \n",
    "        features (int): How many latent features we want to compute.\n",
    "    \n",
    "    Returns:     \n",
    "        X (csr_matrix): user vectors of size users-by-features\n",
    "        \n",
    "        Y (csr_matrix): item vectors of size items-by-features\n",
    "     \"\"\"\n",
    "\n",
    "    assert type(sparse_data) == sparse.csr_matrix, \"Matrix should be sparse in format of csr\"\n",
    "\n",
    "\n",
    "    # Calculate the foncidence for each value in our data\n",
    "    confidence = sparse_data * alpha_val\n",
    "    \n",
    "    # Get the size of user rows and item columns\n",
    "    user_size, item_size = sparse_data.shape\n",
    "    \n",
    "    # We create the user vectors X of size users-by-features, the item vectors\n",
    "    # Y of size items-by-features and randomly assign the values.\n",
    "    X = sparse.csr_matrix(np.random.normal(size = (user_size, features)))\n",
    "    Y = sparse.csr_matrix(np.random.normal(size = (item_size, features)))\n",
    "    \n",
    "    #Precompute I and lambda * I\n",
    "    X_I = sparse.eye(user_size)\n",
    "    Y_I = sparse.eye(item_size)\n",
    "    \n",
    "    I = sparse.eye(features)\n",
    "    lI = lambda_val * I\n",
    "    \n",
    "    for i in tqdm(range(iterations)):\n",
    "        \n",
    "        # Precompute Y-transpose-Y and X-transpose-X\n",
    "        yTy = Y.T @ Y\n",
    "        xTx = X.T @ X\n",
    "\n",
    "        # Loop through all users\n",
    "        for u in range(user_size):\n",
    "\n",
    "            # Get the user row.\n",
    "            u_row = confidence[u,:].toarray() \n",
    "\n",
    "            # Calculate the binary preference p(u)\n",
    "            p_u = u_row.copy()\n",
    "            p_u[p_u != 0] = 1.0\n",
    "\n",
    "            # Calculate Cu and Cu - I\n",
    "            CuI = sparse.diags(u_row, [0])\n",
    "            Cu = CuI + Y_I\n",
    "\n",
    "            # Put it all together and compute the final formula\n",
    "            yT_CuI_y = Y.T @ CuI @ Y\n",
    "            yT_Cu_pu = Y.T @ Cu @ p_u.T\n",
    "            X[u] = spsolve(yTy + yT_CuI_y + lI, yT_Cu_pu)\n",
    "\n",
    "    \n",
    "        for i in range(item_size):\n",
    "\n",
    "            # Get the item column and transpose it.\n",
    "            i_row = confidence[:,i].T.toarray()\n",
    "\n",
    "            # Calculate the binary preference p(i)\n",
    "            p_i = i_row.copy()\n",
    "            p_i[p_i != 0] = 1.0\n",
    "\n",
    "            # Calculate Ci and Ci - I\n",
    "            CiI = sparse.diags(i_row, [0])\n",
    "            Ci = CiI + X_I\n",
    "\n",
    "            # Put it all together and compute the final formula\n",
    "            xT_CiI_x = X.T @ CiI @ X\n",
    "            xT_Ci_pi = X.T @ Ci @ p_i.T\n",
    "            Y[i] = spsolve(xTx + xT_CiI_x + lI, xT_Ci_pi)\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def recommend(user_id, data_sparse, user_vecs, item_vecs):\n",
    "    \"\"\"Recommend items for a given user given a trained model\n",
    "    \n",
    "    Args:\n",
    "        user_id (int): The id of the user we want to create recommendations for.\n",
    "        \n",
    "        data_sparse (csr_matrix): Our original training data.\n",
    "        \n",
    "        user_vecs (csr_matrix): The trained user x features vectors\n",
    "        \n",
    "        item_vecs (csr_matrix): The trained item x features vectors\n",
    "        \n",
    "        item_lookup (pandas.DataFrame): Used to map artist ids to artist names\n",
    "        \n",
    "        num_items (int): How many recommendations we want to return:\n",
    "        \n",
    "    Returns:\n",
    "        recommendations (pandas.DataFrame): DataFrame with num_items artist names and scores\n",
    "    \n",
    "    \"\"\"\n",
    "  \n",
    "    # Get all interactions by the user\n",
    "    user_interactions = data_sparse[user_id,:].toarray()\n",
    "\n",
    "    # We don't want to recommend items the user has consumed. So let's\n",
    "    # set them all to 0 and the unknowns to 1.\n",
    "    user_interactions = user_interactions.reshape(-1) + 1 #Reshape to turn into 1D array\n",
    "    user_interactions[user_interactions > 1] = 0\n",
    "\n",
    "    # This is where we calculate the recommendation by taking the \n",
    "    # dot-product of the user vectors with the item vectors.\n",
    "    rec_vector = (user_vecs[user_id,:] @ item_vecs.T).toarray()\n",
    "\n",
    "    # Let's scale our scores between 0 and 1 to make it all easier to interpret.\n",
    "    min_max = MinMaxScaler()\n",
    "    rec_vector_scaled = min_max.fit_transform(rec_vector.reshape(-1, 1))[:,0]\n",
    "    recommend_vector = user_interactions * rec_vector_scaled\n",
    "   \n",
    "    # Get all the artist indices in order of recommendations (descending) and\n",
    "    # select only the top \"num_items\" items. \n",
    "    item_idx = np.argsort(recommend_vector)[::-1]\n",
    "\n",
    "    movies = []\n",
    "    scores = []\n",
    "\n",
    "    # Loop through our recommended artist indicies and look up the actial artist name\n",
    "    for idx in item_idx:\n",
    "        movies.append(idx)\n",
    "        scores.append(recommend_vector[idx])\n",
    "\n",
    "    # Create a new dataframe with recommended artist names and scores\n",
    "    recommendations = pd.DataFrame({'movies': movies, 'score': scores})\n",
    "    \n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "258b0359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87699837ffa24661b97df63cba48b4c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "als_res_dict = dict()\n",
    "\n",
    "for ds in dict_df_rating:\n",
    "    sparse_local = dict_df_rating[ds]['sparse']\n",
    "    user_vecs, item_vecs = implicit_als(sparse_local, iterations=1, features=20, alpha_val=40)\n",
    "    als_res_dict[ds] = (user_vecs, item_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fc4d949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_lookup = df_ratings[['user_id', 'object_id']]\n",
    "# item_lookup['object_id'] = item_lookup.object_id.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9aee6e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Recall20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall50</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG100</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [Recall20, Recall50, NDCG100]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_metrix_res = pd.DataFrame([], index = ['Recall20', 'Recall50', 'NDCG100'])\n",
    "all_metrix_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d43bdf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(actual, predicted, k):\n",
    "    act_set = set(actual)\n",
    "    pred_set = set(predicted[:k])\n",
    "    result = len(act_set & pred_set) / float(len(act_set))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98b97150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c26888987064421803f44e58fcc8ced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6040 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for ds in dict_df_rating:\n",
    "    df_ratings = dict_df_rating[ds]['original']\n",
    "    all_users = df_ratings.user_id.unique()\n",
    "    user_vecs_loc, item_vecs_loc = als_res_dict[ds]\n",
    "    \n",
    "    rec20_list = []\n",
    "    rec50_list = []\n",
    "    NDCG_list = []\n",
    "    \n",
    "    for user_id in tqdm(all_users):\n",
    "        recommendations = recommend(user_id, data_sparse, user_vecs_loc, item_vecs_loc)\n",
    "        dense_ratings_user = df_ratings[(df_ratings['user_id'] == user_id)& (df_ratings['rating'] > 0)]\n",
    "        \n",
    "        compilation = dense_ratings_user.join(recommendations, on='object_id', how='inner')\n",
    "        compilation['score']  = compilation.score*5\n",
    "        compilation['score_round'] = round(compilation.score).astype(int)\n",
    "        \n",
    "        rec20 = recall(compilation.rating.values, compilation.score_round.values, k=20)\n",
    "        rec50 = recall(compilation.rating.values, compilation.score_round.values, k=50)\n",
    "        NDCG = ndcg(compilation.rating.values.reshape((1, -1)), compilation.score_round.values.reshape((1, -1)), k=100)\n",
    "        \n",
    "        rec20_list.append(rec20)\n",
    "        rec50_list.append(rec50)\n",
    "        NDCG_list.append(NDCG)\n",
    "        \n",
    "    mertix = []\n",
    "    for lst in [rec20_list, rec50_list, NDCG_list]:\n",
    "        mertix.append(np.mean(lst))\n",
    "        \n",
    "    all_metrix_res['ALS'] = mertix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69e974e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Recall20</th>\n",
       "      <td>0.395224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall50</th>\n",
       "      <td>0.532235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG100</th>\n",
       "      <td>0.873256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ALS\n",
       "Recall20  0.395224\n",
       "Recall50  0.532235\n",
       "NDCG100   0.873256"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_metrix_res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
