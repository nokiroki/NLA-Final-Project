{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse.linalg as splin\n",
    "import scipy.sparse as sparse\n",
    "import scipy.sparse.linalg as splg\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import ndcg_score as ndcg\n",
    "\n",
    "# from ignite.metrics.recall import Recall as t_recall\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cephfs/projects/psoker/.local/lib/python3.8/site-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "dict_df_rating = dict()\n",
    "\n",
    "#20 millions\n",
    "\n",
    "# #links = pd.read_csv('ml-20m/links.csv')\n",
    "# df_ratings = pd.read_csv('ml-20m/ratings.csv')\n",
    "# df_ratings.columns = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "# df_ratings.head()\n",
    "\n",
    "\n",
    "#1 million MovieLens \n",
    "\n",
    "df_ratings = pd.read_csv('ml-1m/ratings.dat', sep=\"::\", header=None)\n",
    "df_ratings.columns = ['user_id', 'object_id', 'rating', 'timestamp']\n",
    "df_ratings.drop('timestamp', axis='columns', inplace=True)\n",
    "df_ratings.dropna(inplace=True)\n",
    "df_ratings['user_id'] = df_ratings['user_id'].astype(\"category\").cat.codes\n",
    "df_ratings['object_id'] = df_ratings['object_id'].astype(\"category\").cat.codes\n",
    "\n",
    "dict_df_rating['ML1M'] = dict()\n",
    "dict_df_rating['ML1M']['original'] = df_ratings\n",
    "\n",
    "#Books http://www2.informatik.uni-freiburg.de/~cziegler/BX/\n",
    "\n",
    "#df_ratings = pd.read_csv('Books Data/BX-Book-Ratings.csv', sep=';')\n",
    "df_ratings = pd.read_csv('Books Data/BX-Book-Ratings_short.csv', sep=';')\n",
    "df_ratings.columns = ['user_id', 'object_id', 'rating']\n",
    "df_ratings.dropna(inplace=True)\n",
    "df_ratings['user_id'] = df_ratings['user_id'].astype(\"category\").cat.codes\n",
    "df_ratings['object_id'] = df_ratings['object_id'].astype(\"category\").cat.codes\n",
    "\n",
    "\n",
    "dict_df_rating['BX'] = dict()\n",
    "dict_df_rating['BX']['original'] = df_ratings\n",
    "\n",
    "#Music  http://jmcauley.ucsd.edu/data/amazon/\n",
    "\n",
    "#df_ratings = pd.read_csv('Digital music/ratings_Digital_Music.csv', sep=',', header=None)\n",
    "df_ratings = pd.read_csv('Digital music/ratings_Digital_Music_short.csv', sep=',', header=None)\n",
    "df_ratings.columns = ['user_id', 'object_id', 'rating', 'timestamp']\n",
    "df_ratings.drop('timestamp', axis='columns', inplace=True)\n",
    "df_ratings.dropna(inplace=True)\n",
    "df_ratings['user_id'] = df_ratings['user_id'].astype(\"category\").cat.codes\n",
    "df_ratings['object_id'] = df_ratings['object_id'].astype(\"category\").cat.codes\n",
    "\n",
    "\n",
    "dict_df_rating['DM'] = dict()\n",
    "dict_df_rating['DM']['original'] = df_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparcity for ML1M dataset: 0.044683625622312845\n",
      "sparcity for BX dataset: 0.0022166389175659485\n",
      "sparcity for DM dataset: 0.0014640480404597422\n"
     ]
    }
   ],
   "source": [
    "for ds in dict_df_rating:\n",
    "    df_ratings = dict_df_rating[ds]['original']\n",
    "    all_cells = df_ratings.object_id.nunique() * df_ratings.user_id.nunique()\n",
    "    sparcity_rate = len(df_ratings) / all_cells\n",
    "    print(f'sparcity for {ds} dataset: {sparcity_rate}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 3 4 2 1]\n",
      "[ 0  5  6 10  9  7  8  2  4  3  1]\n",
      "[5. 3. 4. 1. 2.]\n"
     ]
    }
   ],
   "source": [
    "for ds in dict_df_rating:\n",
    "    df_ratings = dict_df_rating[ds]['original']\n",
    "    print(ds, df_ratings.rating.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ds in dict_df_rating:\n",
    "#     print(ds)\n",
    "    \n",
    "#     df_ratings = dict_df_rating[ds]['original'].copy()\n",
    "    \n",
    "#     df_ratings['user_id'] =  df_ratings['user_id'].astype('str')\n",
    "#     df_ratings['object_id'] =  df_ratings['object_id'].astype('str')\n",
    "\n",
    "#     dense_rating = df_ratings.pivot(index='user_id', columns='object_id', values='rating')\n",
    "#     dense_rating = dense_rating.fillna(0)\n",
    "#     dict_df_rating[ds]['dense'] = dense_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML1M\n",
      "BX\n",
      "DM\n"
     ]
    }
   ],
   "source": [
    "#forming sparse matrixes\n",
    "\n",
    "for ds in dict_df_rating:\n",
    "    print(ds)\n",
    "    df_ratings = dict_df_rating[ds]['original'].copy()\n",
    "\n",
    "#     dict_obj = {obj:i for i, obj in enumerate(sorted(df_ratings.object_id.unique()))}\n",
    "#     dict_user = {obj:i for i, obj in enumerate(sorted(df_ratings.user_id.unique()))}\n",
    "\n",
    "#     df_ratings['user_id'] = df_ratings['user_id'].astype(\"category\").cat.codes\n",
    "#     df_ratings['object_id'] = df_ratings['object_id'].astype(\"category\").cat.codes\n",
    "    \n",
    "#     dict_df_rating[ds]['original'] = df_ratings\n",
    "    \n",
    "    rows = df_ratings['user_id'].astype(\"int\")\n",
    "    cols = df_ratings['object_id'].astype(\"int\")\n",
    "\n",
    "    ratings = df_ratings.rating.astype(\"int\")\n",
    "    \n",
    "    data_sparse = sparse.csr_matrix((ratings, (rows, cols)), shape=(df_ratings.user_id.nunique(), \n",
    "                                                                df_ratings.object_id.nunique()), dtype='int32')\n",
    "    \n",
    "    dict_df_rating[ds]['sparse'] = data_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>object_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3082</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4828</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2870</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2194</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3435</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59259</th>\n",
       "      <td>3042</td>\n",
       "      <td>8364</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59260</th>\n",
       "      <td>3042</td>\n",
       "      <td>8365</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59261</th>\n",
       "      <td>3290</td>\n",
       "      <td>8366</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59262</th>\n",
       "      <td>1574</td>\n",
       "      <td>8366</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59263</th>\n",
       "      <td>3298</td>\n",
       "      <td>8366</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59264 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  object_id  rating\n",
       "0         3082          0     5.0\n",
       "1         4828          0     5.0\n",
       "2         2870          0     5.0\n",
       "3         2194          0     5.0\n",
       "4         3435          0     3.0\n",
       "...        ...        ...     ...\n",
       "59259     3042       8364     5.0\n",
       "59260     3042       8365     5.0\n",
       "59261     3290       8366     5.0\n",
       "59262     1574       8366     4.0\n",
       "59263     3298       8366     5.0\n",
       "\n",
       "[59264 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML1M (6040, 3706)\n",
      "BX (11707, 16162)\n",
      "DM (4838, 8367)\n"
     ]
    }
   ],
   "source": [
    "for ds in dict_df_rating:\n",
    "    print(ds, dict_df_rating[ds]['sparse'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(user_id, data_sparse, user_vecs, item_vecs):\n",
    "    \"\"\"Recommend items for a given user given a trained model\n",
    "    \n",
    "    Args:\n",
    "        user_id (int): The id of the user we want to create recommendations for.\n",
    "        \n",
    "        data_sparse (csr_matrix): Our original training data.\n",
    "        \n",
    "        user_vecs (csr_matrix): The trained user x features vectors\n",
    "        \n",
    "        item_vecs (csr_matrix): The trained item x features vectors\n",
    "        \n",
    "        item_lookup (pandas.DataFrame): Used to map artist ids to artist names\n",
    "        \n",
    "        num_items (int): How many recommendations we want to return:\n",
    "        \n",
    "    Returns:\n",
    "        recommendations (pandas.DataFrame): DataFrame with num_items artist names and scores\n",
    "    \n",
    "    \"\"\"\n",
    "  \n",
    "    # Get all interactions by the user\n",
    "    user_interactions = data_sparse[user_id,:].toarray()\n",
    "\n",
    "    # We don't want to recommend items the user has consumed. So let's\n",
    "    # set them all to 0 and the unknowns to 1.\n",
    "    user_interactions = user_interactions.reshape(-1) + 1 #Reshape to turn into 1D array\n",
    "    #user_interactions[user_interactions > 1] = 0\n",
    "\n",
    "    # This is where we calculate the recommendation by taking the \n",
    "    # dot-product of the user vectors with the item vectors.\n",
    "    rec_vector = (user_vecs[user_id,:] @ item_vecs.T).toarray()\n",
    "\n",
    "    # Let's scale our scores between 0 and 1 to make it all easier to interpret.\n",
    "    min_max = MinMaxScaler()\n",
    "    rec_vector_scaled = min_max.fit_transform(rec_vector.reshape(-1, 1))[:,0]\n",
    "    recommend_vector = user_interactions * rec_vector_scaled\n",
    "   \n",
    "    # Get all the artist indices in order of recommendations (descending) and\n",
    "    # select only the top \"num_items\" items. \n",
    "    item_idx = np.argsort(recommend_vector)[::-1]\n",
    "\n",
    "    objects = []\n",
    "    scores = []\n",
    "\n",
    "    # Loop through our recommended artist indicies and look up the actial artist name\n",
    "    for idx in item_idx:\n",
    "        objects.append(idx)\n",
    "        scores.append(recommend_vector[idx])\n",
    "\n",
    "    # Create a new dataframe with recommended artist names and scores\n",
    "    recommendations = pd.DataFrame({'object_id': objects, 'score': scores})\n",
    "    \n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(actual, predicted, k):\n",
    "    act_set = set(actual)\n",
    "    pred_set = set(predicted[:k])\n",
    "    result = len(act_set & pred_set) / float(len(act_set))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrix_res_dict = dict()\n",
    "\n",
    "for ds in dict_df_rating:\n",
    "    all_metrix_res = pd.DataFrame([], index = ['Recall20', 'Recall50', 'NDCG100'])\n",
    "    all_metrix_res_dict[ds] = all_metrix_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def als(sparse_data, alpha_val=40, iterations=10, lambda_val=0.1, features=10):\n",
    "    \"\"\" Implementation of Alternating Least Squares with implicit data. We iteratively\n",
    "    compute the user (x_u) and item (y_i)from tor vectors using the following formulas:\n",
    " \n",
    "    x_u = ((Y.T*Y + Y.T*(Cu - I) * Y) + lambda*I)^-1 * (X.T * Cu * p(u))\n",
    "    y_i = ((X.T*X + X.T*(Ci - I) * X) + lambda*I)^-1 * (Y.T * Ci * p(i))\n",
    " \n",
    "    Args:\n",
    "        sparse_data (csr_matrix): Our sparse user-by-item matrix\n",
    " \n",
    "        alpha_val (int): The rate in which we'll increase our confidence\n",
    "        in a preference with more interactions.\n",
    " \n",
    "        iterations (int): How many times we alternate between fixing and \n",
    "        updating our user and item vectors\n",
    " \n",
    "        lambda_val (float): Regularization value\n",
    " \n",
    "        features (int): How many latent features we want to compute.\n",
    "    \n",
    "    Returns:     \n",
    "        X (csr_matrix): user vectors of size users-by-features\n",
    "        \n",
    "        Y (csr_matrix): item vectors of size items-by-features\n",
    "     \"\"\"\n",
    "\n",
    "    assert type(sparse_data) == sparse.csr_matrix, \"Matrix should be sparse in format of csr\"\n",
    "    \n",
    "    # Get the size of user rows and item columns\n",
    "    user_size, item_size = sparse_data.shape\n",
    "    \n",
    "    # We create the user vectors X of size users-by-features, the item vectors\n",
    "    # Y of size items-by-features and randomly assign the values.\n",
    "    X = sparse.csr_matrix(np.random.normal(size = (user_size, features)))\n",
    "    Y = sparse.csr_matrix(np.random.normal(size = (item_size, features)))\n",
    "\n",
    "    I = sparse.eye(features)\n",
    "    lI = lambda_val * I\n",
    "    \n",
    "    for _ in tqdm(range(iterations)):\n",
    "        \n",
    "        # Precompute Y-transpose-Y and X-transpose-X\n",
    "        yTy = Y.T @ Y\n",
    "        xTx = X.T @ X\n",
    "\n",
    "        # Loop through all users\n",
    "        for u in range(user_size):\n",
    "            u_row = sparse_data[u,:].toarray()\n",
    "            #print(((yTy + lI).shape, (u_row @ Y).T.shape))\n",
    "            X[u] = spsolve(yTy + lI, (u_row @ Y).T)\n",
    "\n",
    "        for i in range(item_size):\n",
    "            i_row = sparse_data[:,i].T.toarray()\n",
    "            Y[i] = spsolve(xTx + lI, (i_row @ X).T)\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "415e5f590fde4633bed843b174d8dd5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dc423bb036649e89c998d55bad195b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d24a18eb2994bc0bb9d3cde1bb9e275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "als_res_dict = dict()\n",
    "\n",
    "for ds in dict_df_rating:\n",
    "    sparse_local = dict_df_rating[ds]['sparse']\n",
    "    user_vecs, item_vecs = als(sparse_local, iterations=15, features=20, alpha_val=40)\n",
    "    als_res_dict[ds] = (user_vecs, item_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('als_vectors.pickle', 'wb') as f:\n",
    "    pickle.dump(als_res_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12f860f66079498f86bb4ef00f399e77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6040.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-832b476fef72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0muser_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_users\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m#print(sparse_local.shape, user_vecs_loc.shape, item_vecs_loc.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mrecommendations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecommend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_local\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_vecs_loc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_vecs_loc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mdense_ratings_user\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_ratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_ratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0muser_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf_ratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rating'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-966b07a0bf4f>\u001b[0m in \u001b[0;36mrecommend\u001b[0;34m(user_id, data_sparse, user_vecs, item_vecs)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# This is where we calculate the recommendation by taking the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# dot-product of the user vectors with the item vectors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mrec_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0muser_vecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mitem_vecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# Let's scale our scores between 0 and 1 to make it all easier to interpret.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__matmul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    562\u001b[0m             raise ValueError(\"Scalar operands are not allowed, \"\n\u001b[1;32m    563\u001b[0m                              \"use '*' instead\")\n\u001b[0;32m--> 564\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__mul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__rmatmul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dimension mismatch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_sparse_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0;31m# If it's a list or whatever, treat it like a matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m_mul_sparse_matrix\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0mmajor_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# convert to this format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         idx_dtype = get_index_dtype((self.indptr, self.indices,\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0marg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                 \u001b[0marg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_self\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36masformat\u001b[0;34m(self, format, copy)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0;31m# Forward the copy kwarg, if it's accepted.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/sparse/csc.py\u001b[0m in \u001b[0;36mtocsr\u001b[0;34m(self, copy)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnnz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         csc_tocsr(M, N,\n\u001b[0m\u001b[1;32m    145\u001b[0m                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for ds in dict_df_rating:\n",
    "    df_ratings = dict_df_rating[ds]['original']\n",
    "    all_users = df_ratings.user_id.unique()\n",
    "    user_vecs_loc, item_vecs_loc = als_res_dict[ds]\n",
    "    sparse_local = dict_df_rating[ds]['sparse']\n",
    "    \n",
    "    rec20_list = []\n",
    "    rec50_list = []\n",
    "    NDCG_list = []\n",
    "    \n",
    "    for user_id in tqdm(all_users):\n",
    "        #print(sparse_local.shape, user_vecs_loc.shape, item_vecs_loc.shape)\n",
    "        recommendations = recommend(user_id, sparse_local, user_vecs_loc, item_vecs_loc)\n",
    "        dense_ratings_user = df_ratings[(df_ratings['user_id'] == user_id) & (df_ratings['rating'] > 0)]\n",
    "        \n",
    "        compilation = pd.merge(dense_ratings_user, recommendations, how='inner', on = 'object_id')\n",
    "        #dense_ratings_user.join(recommendations, on='object_id', how='inner')\n",
    "        compilation['score']  = compilation.score*5\n",
    "        compilation['score_round'] = round(compilation.score).astype(int)\n",
    "        \n",
    "        rec20 = recall(compilation.rating.values, compilation.score_round.values, k=20)\n",
    "        rec50 = recall(compilation.rating.values, compilation.score_round.values, k=50)\n",
    "        NDCG = ndcg(compilation.rating.values.reshape((1, -1)), compilation.score.values.reshape((1, -1)), k=100)\n",
    "        \n",
    "        rec20_list.append(rec20)\n",
    "        rec50_list.append(rec50)\n",
    "        NDCG_list.append(NDCG)\n",
    "        \n",
    "    mertix = []\n",
    "    for lst in [rec20_list, rec50_list, NDCG_list]:\n",
    "        mertix.append(np.mean(lst))\n",
    "        \n",
    "    all_metrix_res_dict[ds]['ALS'] = mertix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALS++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alspp(sparse_data, alpha_val=40, iterations=10, lambda_val=0.1, features=10):\n",
    "    \"\"\" Implementation of Alternating Least Squares with implicit data. We iteratively\n",
    "    compute the user (x_u) and item (y_i)from tor vectors using the following formulas:\n",
    " \n",
    "    x_u = ((Y.T*Y + Y.T*(Cu - I) * Y) + lambda*I)^-1 * (X.T * Cu * p(u))\n",
    "    y_i = ((X.T*X + X.T*(Ci - I) * X) + lambda*I)^-1 * (Y.T * Ci * p(i))\n",
    " \n",
    "    Args:\n",
    "        sparse_data (csr_matrix): Our sparse user-by-item matrix\n",
    " \n",
    "        alpha_val (int): The rate in which we'll increase our confidence\n",
    "        in a preference with more interactions.\n",
    " \n",
    "        iterations (int): How many times we alternate between fixing and \n",
    "        updating our user and item vectors\n",
    " \n",
    "        lambda_val (float): Regularization value\n",
    " \n",
    "        features (int): How many latent features we want to compute.\n",
    "    \n",
    "    Returns:     \n",
    "        X (csr_matrix): user vectors of size users-by-features\n",
    "        \n",
    "        Y (csr_matrix): item vectors of size items-by-features\n",
    "     \"\"\"\n",
    "\n",
    "    assert type(sparse_data) == sparse.csr_matrix, \"Matrix should be sparse in format of csr\"\n",
    "    \n",
    "    # Get the size of user rows and item columns\n",
    "    user_size, item_size = sparse_data.shape\n",
    "    \n",
    "    # We create the user vectors X of size users-by-features, the item vectors\n",
    "    # Y of size items-by-features and randomly assign the values.\n",
    "    X = sparse.csr_matrix(np.random.normal(size = (user_size, features)))\n",
    "    Y = sparse.csr_matrix(np.random.normal(size = (item_size, features)))\n",
    "    \n",
    "#     I = sparse.csr_matrix((np.ones(features), (np.ones(features), np.ones(features))), \n",
    "#                            shape=(features, features), dtype='int32')\n",
    "#     #I = sparse.eye(features)\n",
    "#     lI = lambda_val * I\n",
    "    \n",
    "    for _ in tqdm(range(iterations)):\n",
    "        #print(Y.shape)\n",
    "        \n",
    "        # Precompute Y-transpose-Y and X-transpose-X\n",
    "        ind_rand = list(set(random.choices(list(range(features)), weights=None, k=features//2)))\n",
    "        Y_rand = Y[:, ind_rand]\n",
    "        X_rand = X[:, ind_rand]\n",
    "        \n",
    "        lI = lambda_val * sparse.eye(len(ind_rand))\n",
    "        \n",
    "        yTy = Y_rand.T @ Y_rand\n",
    "        xTx = X_rand.T @ X_rand\n",
    "\n",
    "        # Loop through all users\n",
    "        for u in range(user_size):\n",
    "            u_row = sparse_data[u,:].toarray()\n",
    "            X[u, ind_rand] = spsolve(yTy + lI, (u_row @ Y_rand).T)\n",
    "\n",
    "        for i in range(item_size):\n",
    "            i_row = sparse_data[:,i].T.toarray()\n",
    "            Y[i, ind_rand] = spsolve(xTx + lI, (i_row @ X_rand).T)\n",
    "\n",
    "    return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alspp_res_dict = dict()\n",
    "\n",
    "for ds in dict_df_rating:\n",
    "    sparse_local = dict_df_rating[ds]['sparse']\n",
    "    user_vecs, item_vecs = alspp(sparse_local, iterations=15, features=20, alpha_val=40)\n",
    "    alspp_res_dict[ds] = (user_vecs, item_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('alspp_vectors.pickle', 'wb') as f:\n",
    "#     pickle.dump(alspp_res_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds in dict_df_rating:\n",
    "    df_ratings = dict_df_rating[ds]['original']\n",
    "    all_users = df_ratings.user_id.unique()\n",
    "    user_vecs_loc, item_vecs_loc = alspp_res_dict[ds]\n",
    "    \n",
    "    rec20_list = []\n",
    "    rec50_list = []\n",
    "    NDCG_list = []\n",
    "    \n",
    "    for user_id in tqdm(all_users):\n",
    "        recommendations = recommend(user_id, data_sparse, user_vecs_loc, item_vecs_loc)\n",
    "        dense_ratings_user = df_ratings[(df_ratings['user_id'] == user_id) & (df_ratings['rating'] > 0)]\n",
    "        \n",
    "        compilation = pd.merge(dense_ratings_user, recommendations, how='inner', on = 'object_id')\n",
    "        #dense_ratings_user.join(recommendations, on='object_id', how='inner')\n",
    "        compilation['score']  = compilation.score*5\n",
    "        compilation['score_round'] = round(compilation.score).astype(int)\n",
    "        \n",
    "        rec20 = recall(compilation.rating.values, compilation.score_round.values, k=20)\n",
    "        rec50 = recall(compilation.rating.values, compilation.score_round.values, k=50)\n",
    "        NDCG = ndcg(compilation.rating.values.reshape((1, -1)), compilation.score.values.reshape((1, -1)), k=100)\n",
    "        \n",
    "        rec20_list.append(rec20)\n",
    "        rec50_list.append(rec50)\n",
    "        NDCG_list.append(NDCG)\n",
    "        \n",
    "    mertix = []\n",
    "    for lst in [rec20_list, rec50_list, NDCG_list]:\n",
    "        mertix.append(np.mean(lst))\n",
    "        \n",
    "    all_metrix_res_dict[ds]['ALSPP'] = mertix\n",
    "\n",
    "all_metrix_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALS with bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def biased_als(data, iterations, lmbda, features):\n",
    "\n",
    "    user_size, item_size = data.shape\n",
    "    \n",
    "    X = sparse.csr_matrix(np.random.normal(size = (user_size, features+1)))\n",
    "    Y = sparse.csr_matrix(np.random.normal(size = (features+1, item_size)))\n",
    "    \n",
    "    beta = np.zeros((1, user_size))\n",
    "    gamma = np.zeros((1, item_size))\n",
    "    \n",
    "    I = sparse.eye(features+1)\n",
    "    lI = lmbda * I\n",
    "    \n",
    "    for _ in tqdm(range(iterations)):\n",
    "        \n",
    "        X_wave = X.copy()\n",
    "        #print(X_wave[:, 0].shape, np.ones((1, user_size)).shape)\n",
    "        X_wave[:, 0] = np.ones((user_size, 1))\n",
    "        Y_wave = Y.copy()\n",
    "        Y_wave[0,:] = gamma\n",
    "        \n",
    "\n",
    "        xTx = X_wave.T @ X_wave\n",
    "\n",
    "        for i in range(item_size):\n",
    "            \n",
    "            r_i = data[:, i].T.toarray()\n",
    "            r_i_beta = r_i - beta\n",
    "            \n",
    "#             print('I r i shape', r_i.shape)\n",
    "#             print('I r i beta shape', r_i_beta.shape)\n",
    "#             print('I X_wave shape', X_wave.shape)\n",
    "#             print('I Y_wave shape', Y_wave.shape, '\\n')\n",
    "            \n",
    "            Y[:,i] = spsolve(xTx + lI, (r_i_beta @ X_wave).T)\n",
    "            #Y[:,i] = splg.inv(X_wave.T @ X_wave + lmbda * sparse.eye(features+1)) @ X_wave.T @ r_i_beta.T\n",
    "        \n",
    "        yTy = Y_wave @ Y_wave.T\n",
    "        Y_wave = Y.copy()\n",
    "        Y_wave[0, :] = np.ones((1, item_size))\n",
    "        X_wave = X.copy()\n",
    "        X_wave[:,0] = beta    \n",
    "        for u in range(user_size):\n",
    "            r_u = data[u, :].toarray()\n",
    "            r_u_gamma = r_u - gamma\n",
    "            \n",
    "#             print('U r u shape', r_u.shape)\n",
    "#             print('U r u gamma shape', r_u_gamma.shape)\n",
    "#             print('U X_wave shape', X_wave.shape)\n",
    "#             print('U Y_wave shape', Y_wave.shape)\n",
    "#             print('\\n\\n')\n",
    "\n",
    "            X[u,:] = spsolve(Y_wave @ Y_wave.T + lI, Y_wave @ r_u_gamma.T)\n",
    "            #X[u,:] = splg.inv(Y_wave @ Y_wave.T + lmbda*sparse.eye(features+1)) @ Y_wave @ r_u_gamma.T\n",
    "            \n",
    "    return X, Y.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a951e3bcfb5d4fc5a25270b004e0833c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0711802ac616461e9ade256d53bd41e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "als_bias_res_dict = dict()\n",
    "\n",
    "for ds in dict_df_rating:\n",
    "    sparse_local = dict_df_rating[ds]['sparse']\n",
    "    user_vecs, item_vecs = biased_als(sparse_local, iterations=15, features=20, lmbda=10)\n",
    "    als_bias_res_dict[ds] = (user_vecs, item_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('als_bias_vectors.pickle', 'wb') as f:\n",
    "#     pickle.dump(als_bias_res_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evaluation(dict_with_res, method_name):\n",
    "    for ds in dict_df_rating:\n",
    "        df_ratings = dict_df_rating[ds]['original']\n",
    "        all_users = df_ratings.user_id.unique()\n",
    "        user_vecs_loc, item_vecs_loc = dict_with_res[ds]\n",
    "        sparse_local = dict_df_rating[ds]['sparse']\n",
    "\n",
    "        rec20_list = []\n",
    "        rec50_list = []\n",
    "        NDCG_list = []\n",
    "\n",
    "        for user_id in tqdm(all_users):\n",
    "            recommendations = recommend(user_id, sparse_local, user_vecs_loc, item_vecs_loc)\n",
    "            dense_ratings_user = df_ratings[(df_ratings['user_id'] == user_id) & (df_ratings['rating'] > 0)]\n",
    "    \n",
    "            compilation = pd.merge(dense_ratings_user, recommendations, how='inner', on = 'object_id')\n",
    "            \n",
    "            if len(compilation) < 2:\n",
    "                continue\n",
    "            #dense_ratings_user.join(recommendations, on='object_id', how='inner')\n",
    "            compilation['score']  = compilation.score*5\n",
    "            compilation['score_round'] = round(compilation.score).astype(int)\n",
    "\n",
    "            rec20 = recall(compilation.rating.values, compilation.score_round.values, k=20)\n",
    "            rec50 = recall(compilation.rating.values, compilation.score_round.values, k=50)\n",
    "            NDCG = ndcg(compilation.rating.values.reshape((1, -1)), compilation.score.values.reshape((1, -1)), k=100)\n",
    "\n",
    "            rec20_list.append(rec20)\n",
    "            rec50_list.append(rec50)\n",
    "            NDCG_list.append(NDCG)\n",
    "\n",
    "        mertix = []\n",
    "        for lst in [rec20_list, rec50_list, NDCG_list]:\n",
    "            mertix.append(np.mean(lst))\n",
    "\n",
    "        all_metrix_res_dict[ds][method_name] = mertix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2155a2078ee74954b106f9fb17aa2b61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6040.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5308a45443ce427199c31ea75fa2ec3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11707.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd5d7f9d68e8477ebe0cf33ca86cc131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4838.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with open('als_bias_vectors.pickle', 'rb') as f:\n",
    "    als_bias_res_dict = pickle.load(f)\n",
    "\n",
    "get_evaluation(als_bias_res_dict, 'ALS_bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e36656983ee490592231118ca7f94fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6040.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('als_vectors.pickle', 'rb') as f:\n",
    "    als_res_dict = pickle.load(f)\n",
    "\n",
    "get_evaluation(als_res_dict, 'ALS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edc51842b7c24010b783c17ac710cd80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6040.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdd0d08d24d14a38898e0297e0f6cd70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11707.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f581a6a23e5d4188be2444274db2d5fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4838.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with open('alspp_vectors.pickle', 'rb') as f:\n",
    "    alspp_res_dict = pickle.load(f)\n",
    "\n",
    "get_evaluation(alspp_res_dict, 'ALSPP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML1M\n",
      "          ALS_bias     ALSPP\n",
      "Recall20  0.502870  0.334421\n",
      "Recall50  0.696623  0.476719\n",
      "NDCG100   0.967787  0.960765\n",
      "BX\n",
      "          ALS_bias     ALSPP\n",
      "Recall20  0.159582  0.090857\n",
      "Recall50  0.174330  0.094478\n",
      "NDCG100   0.982831  0.993770\n",
      "DM\n",
      "          ALS_bias     ALSPP\n",
      "Recall20  0.122520  0.078996\n",
      "Recall50  0.137759  0.088320\n",
      "NDCG100   0.991055  0.995574\n"
     ]
    }
   ],
   "source": [
    "for ds in dict_df_rating:\n",
    "    print(ds)\n",
    "    print(all_metrix_res_dict[ds], end='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
