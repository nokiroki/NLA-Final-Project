{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse.linalg as splin\n",
    "import scipy.sparse as sparse\n",
    "import json\n",
    "\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import ndcg_score as ndcg\n",
    "from sklearn.metrics import recall_score as recall\n",
    "# from ignite.metrics.recall import Recall as t_recall\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>object_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1104</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>639</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>853</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3177</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2162</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000204</th>\n",
       "      <td>6039</td>\n",
       "      <td>1019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000205</th>\n",
       "      <td>6039</td>\n",
       "      <td>1022</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000206</th>\n",
       "      <td>6039</td>\n",
       "      <td>548</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000207</th>\n",
       "      <td>6039</td>\n",
       "      <td>1024</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000208</th>\n",
       "      <td>6039</td>\n",
       "      <td>1025</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000209 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  object_id  rating\n",
       "0              0       1104       5\n",
       "1              0        639       3\n",
       "2              0        853       3\n",
       "3              0       3177       4\n",
       "4              0       2162       5\n",
       "...          ...        ...     ...\n",
       "1000204     6039       1019       1\n",
       "1000205     6039       1022       5\n",
       "1000206     6039        548       5\n",
       "1000207     6039       1024       4\n",
       "1000208     6039       1025       4\n",
       "\n",
       "[1000209 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 million MovieLens \n",
    "\n",
    "df_ratings = pd.read_csv('ml-1m/ratings.dat', sep=\"::\", header=None)\n",
    "df_ratings.columns = ['user_id', 'object_id', 'rating', 'timestamp']\n",
    "df_ratings.drop('timestamp', axis='columns', inplace=True)\n",
    "df_ratings.dropna(inplace=True)\n",
    "df_ratings['user_id'] = df_ratings['user_id'].astype(\"category\").cat.codes\n",
    "df_ratings['object_id'] = df_ratings['object_id'].astype(\"category\").cat.codes\n",
    "df_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_sparse_matrix(df, rows='user_id', columns='object_id'):\n",
    "    rows = df[rows].astype(\"int\")\n",
    "    cols = df[columns].astype(\"int\")\n",
    "\n",
    "    ratings = df.rating.astype(\"int\")\n",
    "\n",
    "    data_sparse = sparse.csr_matrix(\n",
    "        (ratings, (rows, cols)), \n",
    "        shape=(\n",
    "            df.user_id.nunique(), \n",
    "            df.object_id.nunique() \n",
    "        ), \n",
    "        dtype='int32'\n",
    "    )\n",
    "\n",
    "    return data_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, user_col, item_col='object_id', test_size=0.5):\n",
    "    random.seed(123)\n",
    "    test_indices = []\n",
    "    for user in df[user_col].unique():\n",
    "        df1 = df[df[user_col] == user]\n",
    "        test_ind = random.sample(df[item_col].index.tolist(), k=int(len(df1)*test_size))\n",
    "        test_indices.extend(test_ind)\n",
    "    test_data = df.iloc[test_indices]\n",
    "    train_data = df.drop(test_indices, axis=0)\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 6037, 6038, 6039], dtype=int16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings['user_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((607814, 3), (498623, 3))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data = train_test_split(df_ratings, 'user_id', item_col='object_id', test_size=0.5)\n",
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1106437"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape[0] + test_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set() True\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    set(test_data.index) & set(train_data.index), \n",
    "    (sorted(list(set(test_data.index) | set(train_data.index))) == df_ratings.index).sum() == len(df_ratings)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sparse(df, user_col, item_col, rating_col):\n",
    "    print(df[rating_col].shape, df[user_col].nunique(), df_ratings[item_col].nunique())\n",
    "    data_sparse = sparse.csr_matrix(\n",
    "        (\n",
    "            df[rating_col].values, \n",
    "            (df[user_col].values, df[item_col].values)\n",
    "        ), \n",
    "#         shape=(\n",
    "#             df[user_col].nunique(), df_ratings[item_col].nunique()\n",
    "#         )\n",
    "    ) # почему -1????????\n",
    "\n",
    "    return data_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000209,) 6040 3706\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<6040x3706 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1000209 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sparse = create_sparse(df_ratings, 'user_id', 'object_id', 'rating')\n",
    "df_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for u in df_ratings['user_id']:\n",
    "#     if len(df_ratings[df_ratings['user_id'] == u]) < 2:\n",
    "#         print(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(607814,) 6040 3706\n",
      "(498623,) 6040 3706\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<6040x3706 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 607814 stored elements in Compressed Sparse Row format>,\n",
       " <6040x3706 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 392395 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sparse = create_sparse(train_data, 'user_id', 'object_id', 'rating')\n",
    "test_sparse = create_sparse(test_data, 'user_id', 'object_id', 'rating')\n",
    "train_sparse, test_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class iALS:\n",
    "    def __init__(self, alpha_val=40, iterations=10, lambda_val=0.1, features=10):\n",
    "        self.alpha_val = alpha_val\n",
    "        self.iterations = iterations\n",
    "        self.lambda_val = lambda_val\n",
    "        self.features = features\n",
    "    \n",
    "    def fit(self, train_sparse_data):\n",
    "        \"\"\" Implementation of Alternating Least Squares with implicit data. We iteratively\n",
    "        compute the user (x_u) and item (y_i) from tor vectors using the following formulas:\n",
    "\n",
    "        x_u = ((Y.T*Y + Y.T*(Cu - I) * Y) + lambda*I)^-1 * (X.T * Cu * p(u))\n",
    "        y_i = ((X.T*X + X.T*(Ci - I) * X) + lambda*I)^-1 * (Y.T * Ci * p(i))\n",
    "\n",
    "        Args:\n",
    "            train_sparse_data (sparse.csr_matrix): Our sparse user-by-item matrix\n",
    "            self.alpha_val (int): The rate in which we'll increase our confidence in a preference with more interactions\n",
    "            self.iterations (int): How many times we alternate between fixing and updating our user and item vectors\n",
    "            self.lambda_val (float): Regularization value\n",
    "            self.features (int): How many latent self.features we want to compute\n",
    "\n",
    "        Returns:     \n",
    "            X (sparse.csr_matrix): user vectors of size users-by-self.features\n",
    "            Y (sparse.csr_matrix): item vectors of size items-by-self.features\n",
    "         \"\"\"\n",
    "\n",
    "        assert type(train_sparse_data) == sparse.csr_matrix, \"Matrix should be sparse in format of csr\"\n",
    "\n",
    "\n",
    "        # Calculate the foncidence for each value in our data\n",
    "        confidence = train_sparse_data * self.alpha_val\n",
    "\n",
    "        # Get the size of user rows and item columns\n",
    "        user_size, item_size = train_sparse_data.shape\n",
    "\n",
    "        # We create the user vectors X of size users-by-self.features, the item vectors\n",
    "        # Y of size items-by-self.features and randomly assign the values.\n",
    "        X = sparse.csr_matrix(np.random.normal(size = (user_size, self.features)))\n",
    "        Y = sparse.csr_matrix(np.random.normal(size = (item_size, self.features)))\n",
    "\n",
    "        # Precompute I and lambda * I\n",
    "        X_I = sparse.eye(user_size)\n",
    "        Y_I = sparse.eye(item_size)\n",
    "\n",
    "        I = sparse.eye(self.features)\n",
    "        lI = self.lambda_val * I\n",
    "\n",
    "        for i in tqdm(range(self.iterations)):\n",
    "            # Precompute Y-transpose-Y and X-transpose-X\n",
    "            yTy = Y.T @ Y\n",
    "            xTx = X.T @ X\n",
    "\n",
    "            # Loop through all users\n",
    "            for u in range(user_size):\n",
    "\n",
    "                # Get the user row.\n",
    "                u_row = confidence[u,:].toarray() \n",
    "\n",
    "                # Calculate the binary preference p(u)\n",
    "                p_u = u_row.copy()\n",
    "                p_u[p_u != 0] = 1.0\n",
    "\n",
    "                # Calculate Cu and Cu - I\n",
    "                CuI = sparse.diags(u_row, [0])\n",
    "                Cu = CuI + Y_I\n",
    "\n",
    "                # Put it all together and compute the final formula\n",
    "                yT_CuI_y = Y.T @ CuI @ Y\n",
    "                yT_Cu_pu = Y.T @ Cu @ p_u.T\n",
    "                X[u] = spsolve(yTy + yT_CuI_y + lI, yT_Cu_pu)\n",
    "\n",
    "\n",
    "            for i in range(item_size):\n",
    "                # Get the item column and transpose it.\n",
    "                i_row = confidence[:,i].T.toarray()\n",
    "\n",
    "                # Calculate the binary preference p(i)\n",
    "                p_i = i_row.copy()\n",
    "                p_i[p_i != 0] = 1.0\n",
    "\n",
    "                # Calculate Ci and Ci - I\n",
    "                CiI = sparse.diags(i_row, [0])\n",
    "                Ci = CiI + X_I\n",
    "\n",
    "                # Put it all together and compute the final formula\n",
    "                xT_CiI_x = X.T @ CiI @ X\n",
    "                xT_Ci_pi = X.T @ Ci @ p_i.T\n",
    "                Y[i] = spsolve(xTx + xT_CiI_x + lI, xT_Ci_pi)\n",
    "\n",
    "        return X, Y\n",
    "    \n",
    "    def predict(self, user_id, data_sparse, user_vecs, item_vecs, item_lookup):\n",
    "        \"\"\"Recommend items for a given user given a trained model\n",
    "\n",
    "        Args:\n",
    "            user_id (int): The id of the user we want to create recommendations for\n",
    "            data_sparse (sparse.csr_matrix): Our original training data\n",
    "            user_vecs (sparse.csr_matrix): The trained user x self.features vectors\n",
    "            item_vecs (sparse.csr_matrix): The trained item x self.features vectors\n",
    "            item_lookup (pd.DataFrame): Used to map artist ids to artist names\n",
    "            num_items (int): How many recommendations we want to return:\n",
    "\n",
    "        Returns:\n",
    "            recommendations (pandas.DataFrame): DataFrame with num_items artist names and scores\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Get all interactions by the user\n",
    "        user_interactions = data_sparse[user_id,:].toarray()\n",
    "\n",
    "        # We don't want to recommend items the user has consumed. So let's\n",
    "        # set them all to 0 and the unknowns to 1.\n",
    "        user_interactions = user_interactions.reshape(-1) + 1 #Reshape to turn into 1D array\n",
    "        user_interactions[user_interactions > 1] = 0\n",
    "\n",
    "        # This is where we calculate the recommendation by taking the \n",
    "        # dot-product of the user vectors with the item vectors.\n",
    "        rec_vector = (user_vecs[user_id,:] @ item_vecs.T).toarray()\n",
    "\n",
    "        # Let's scale our scores between 0 and 1 to make it all easier to interpret.\n",
    "        min_max = MinMaxScaler()\n",
    "        rec_vector_scaled = min_max.fit_transform(rec_vector.reshape(-1, 1))[:,0]\n",
    "        recommend_vector = user_interactions * rec_vector_scaled\n",
    "\n",
    "        # Get all the artist indices in order of recommendations (descending) and\n",
    "        # select only the top \"num_items\" items. \n",
    "        item_idx = np.argsort(recommend_vector)[::-1]\n",
    "\n",
    "        movies = []\n",
    "        scores = []\n",
    "\n",
    "        # Loop through our recommended artist indicies and look up the actial artist name\n",
    "        for idx in item_idx:\n",
    "            movies.append(item_lookup.object_id.loc[item_lookup.movie_num == str(idx)].iloc[0])\n",
    "            scores.append(recommend_vector[idx])\n",
    "\n",
    "        # Create a new dataframe with recommended artist names and scores\n",
    "        recommendations = pd.DataFrame({'movies': movies, 'score': scores})\n",
    "\n",
    "        return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = iALS(iterations=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "922f10fe1ae0466b8d958e1794c95340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "user_vecs, item_vecs = model.fit(train_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings['movie_num'] = df_ratings['object_id'].astype(\"category\").cat.codes\n",
    "item_lookup = df_ratings[['movie_num', 'object_id']].drop_duplicates()\n",
    "item_lookup['movie_num'] = item_lookup.movie_num.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rec = model.predict(1, test_sparse, user_vecs, item_vecs, item_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(actual, predicted, k):\n",
    "    act_set = set(actual)\n",
    "    pred_set = set(predicted[:k])\n",
    "    result = len(act_set & pred_set) / float(len(act_set))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "187d9edec7924026bdb974c9d90b6f1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_users = df_ratings.user_id.unique()\n",
    "\n",
    "rec20_list = []\n",
    "rec50_list = []\n",
    "NDCG_list = []\n",
    "\n",
    "for user_id in tqdm(all_users[:100]):\n",
    "    recommendations = model.predict(user_id, test_sparse, user_vecs, item_vecs, item_lookup)\n",
    "    dense_ratings_user = test_data[(test_data['user_id'] == user_id) & (test_data['rating'] > 0)]\n",
    "\n",
    "    compilation = pd.merge(dense_ratings_user, recommendations, left_on='object_id', right_on='movies')\n",
    "    compilation['score']  = compilation.score*5\n",
    "    compilation['score_round'] = round(compilation.score).astype(int)\n",
    "\n",
    "    rec20 = recall(compilation.rating.values, compilation.score_round.values, k=20)\n",
    "    rec50 = recall(compilation.rating.values, compilation.score_round.values, k=50)\n",
    "    NDCG = ndcg(compilation.rating.values.reshape((1, -1)), compilation.score_round.values.reshape((1, -1)), k=100)\n",
    "\n",
    "    rec20_list.append(rec20)\n",
    "    rec50_list.append(rec50)\n",
    "    NDCG_list.append(NDCG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0, 0.9063585988048031)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(rec20_list).mean(), np.array(rec50_list).mean(), np.array(NDCG_list).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
